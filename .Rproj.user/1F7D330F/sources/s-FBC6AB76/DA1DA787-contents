
```{r message=FALSE, warning=FALSE}
MAIN_DATA_PATH <- here("writeups/CCRR_CogSci/cogsci_data/tidy_main.csv")
df.main <- read_csv(MAIN_DATA_PATH, col_types = cols(.default = col_character())) %>% 
  mutate(resp = as.numeric(resp))
```

```{r}
df.descriptive <- df.main %>% 
  group_by(task_name, task_info, resp_type, culture) %>% 
  summarise(
    mean = mean(as.numeric(resp), na.rm = TRUE), 
    sd = sd(as.numeric(resp), na.rm = TRUE))
```

## Analytic approach

The sample size, methods, and main analyses were pre-registered and are available at [https://aspredicted.org/blind.php?x=pk887t](https://aspredicted.org/blind.php?x=pk887t). Data and analysis scripts are available at [https://osf.io/65hwd/?view_only=04227ff032ad446fb126fa102ff056d6](https://osf.io/65hwd/?view_only=04227ff032ad446fb126fa102ff056d6). Departing from the heterogeneous approaches used by previous authors, we attempted to follow current best practices by using linear mixed effects models iwth maximal random effect structure [@barr2013], fit to each task. In case of convergence failure, we followed standard operating procedure of pruning random slopes first and then random intercepts, always maintaining random intercepts by participant. We report $p$-values derived from approximating t-scores from z-scores, which is appropriate for relatively large samples [@blouin2004difference]. The majority of results are visualized in Figure 1, except for the Ebbinghaus Illusion data, in Figure 2.


<!-- Additional information on the analysis can be found in Supplemental Information at [https://docs.google.com/document/d/12bU6rZiUCUQQxUVVqy01j6UtBO-fflofdeVhkzv8ApI/edit#](https://docs.google.com/document/d/12bU6rZiUCUQQxUVVqy01j6UtBO-fflofdeVhkzv8ApI/edit#) [need to anonymize].  -->
<!--\textcolor{red}{[add analytic approach section here or SI? E.g., we ran lmes generally, and we always pruned slopes first, and these were the usual fixed effects? For X kind of data, we ran these kinds of glmers? We assessed significance in X way. See our code for details"]}
-->

<!-- \begin{table} -->
<!-- \renewcommand*{\arraystretch}{1.5} -->
<!-- \fontsize{7}{8}\selectfont -->
<!-- \caption{Red and blue represent CN and US data respectively. Tasks showing differential performance by culture are indicated with an asterisk after the title.\label{tab:bigtable}} -->
<!-- \begin{CodeChunk} -->
<!-- \begin{tabular}{p{0.22\textwidth}|p{0.22\textwidth}} -->

<!-- \hline -->
<!-- Task (for all tasks N = 256) & Results\\ -->
<!-- \hline -->
<!--  \textbf{Ambiguous RMTS} \\  Adapted from Carstensen et al., 2019 (N = 116). Plot shows similar preferences for object match (0) over relational match (1) in both groups.  US: \textit{M} = 0.32, SD = 0.47; CN: \textit{M} = 0.38, SD= 0.48 &    \vspace{-.7cm} \raisebox{-.8\height}{\includegraphics[height = 2.8 cm, width=3.5cm]{figs/RMTS}} \\ -->
<!-- \hline -->
<!-- \textbf{Picture Free Description*}\\ Adapted from Imada et al., 2013 (N = 175). Plot  shows  US  par- -->
<!-- ticipants are more likely to mention  focal  objects (left) and provide more descriptive terms overall (right) than CN participants. First mention: US: \textit{M} = 0.90, SD = 0.29; CN; \textit{M} = 0.56, SD = 0.50; Description: US: \textit{M} = 1.25, SD = 1.38; CN: \textit{M} = 0.92, SD = 1.04. &  \vspace{-.7cm}\raisebox{-.8\height}{\includegraphics[height=3.5 cm, width=0.22\textwidth]{figs/FD}} \\ -->
<!-- \hline -->
<!-- \textbf{Ebbinghaus Illusion} \\  Adapted from Imada et al., 2013 (N = 175). Plot shows US participants and CN participants do not differ in their susceptibility to the illusion. No Context block: US: \textit{M} = 0.96, SD = 0.21; CN: \textit{M} = 0.93, SD = 0.25; Illusion block: US: \textit{M} = 0.37, SD = 0.48; CN: \textit{M} = 0.36, SD = 0.48. &  \vspace{-.7cm} \raisebox{-.8\height}{\includegraphics[height = 3 cm, width=0.22\textwidth]{figs/EBB}}\\ -->
<!-- \hline -->
<!-- \textbf{Horizon Collage} \\  Adapted from Senzaki et al., 2014 (N = 376). Plot shows US participants and CN participants do not differ in their placement of the horizon. Horizon height: US: \textit{M} = 0.57, SD = 0.16; CN \textit{M} = 0.54, SD = 0.19. &  \vspace{-.7cm} \raisebox{-.8\height}{\includegraphics[height = 3 cm, width=0.22\textwidth]{figs/HZ}} \\ -->
<!-- \hline -->
<!-- \textbf{Symbolic Self-Inflation} \\ Adapted from Kitayama et al., 2009 (N = 216). Plot shows US participants and CN participants do not differ in their degree of symbolic self-inflation. US: \textit{M} = 0.95, SD = 0.27; CN: \textit{M} = 0.95, SD = 0.55. & \vspace{-.7cm} \raisebox{-.8\height}{\includegraphics[height = 3 cm, width=0.22\textwidth]{figs/SI}} \\ -->
<!-- \hline -->
<!-- \textbf{Uniqueness Preference} \\  Adapted from Kim \& Markus, 1999 (N = 56). Plot shows US participants and CN participants do not differ in their preference for selecting the unique option. US: \textit{M} = 0.57; CN: \textit{M} = 0.63. &\vspace{-.7cm}  \raisebox{-.8\height}{\includegraphics[height = 3 cm, width=0.22\textwidth]{figs/UP}} \\ -->
<!-- \hline -->
<!-- \textbf{Causal Attribution} \\  Adapted from Seiver et al., 2013 (N = 159, US only). Plot shows US participants and CN participants do not differ in their average number of personal attributions (left) and situational attributions (right). Personal attribution: US: \textit{M} = 0.38, SD = 0.62; CN: \textit{M} = 0.48, SD = 0.52; Situational attribution: US: \textit{M} = 0.64, SD = 0.65; CN: \textit{M} = 0.68, SD = 0.51. & \vspace{-.7cm}  \raisebox{-.8\height}{\includegraphics[height = 3.5cm, width=0.22\textwidth]{figs/CA}} \\ -->
<!-- \hline -->
<!-- \end{tabular} -->

<!-- \end{CodeChunk} -->
<!-- \end{table} -->


```{r setup, include=FALSE}
library(cowplot)
library(tidyverse)
library(here)
library(jsonlite)
library(kableExtra)
library(DT)
library(Dict)
library(ggforce)
library(ggimage)
library(tidyboot)
library(lme4)
library(raincloudplots)
library(RColorBrewer)
library(reshape2)
source(here("writeups/CCRR_CogSci/03_scripts/R_rainclouds.R"))

PROCESSED_MAIN_PATH <- here("writeups/CCRR_CogSci/cogsci_data/tidy_main.csv")
tidy_d <- read_csv(PROCESSED_MAIN_PATH)
```

```{r}


EBB_number <- tidy_d %>% 
  group_by(culture, task_info, resp_type) %>% 
  filter(task_name == "EBB") %>% 
  summarise(
    mean = mean(as.numeric(resp)), 
    resp = sd(as.numeric(resp))
  )

HZ_number <- tidy_d %>% 
  group_by(culture, task_info, resp_type) %>% 
  filter(task_name == "HZ") %>% 
  summarise(
    mean = mean(as.numeric(resp)), 
    resp = sd(as.numeric(resp))
  )

SI_number <- tidy_d %>% 
  group_by(culture, task_info, resp_type) %>% 
  filter(task_name == "SI") %>% 
  summarise(
    mean = mean(as.numeric(resp)), 
    resp = sd(as.numeric(resp))
  )

UP_number <- tidy_d %>% 
  group_by(culture, task_info, resp_type) %>% 
  filter(task_name == "CP") %>% 
  summarise(
    mean = mean(as.numeric(resp)), 
    resp = sd(as.numeric(resp))
  )


```


<!-- # Ambiguous RMTS  -->


```{r RMTS_plot}
RMTS_raw <- tidy_d %>% 
  filter(task_name == "RMTS") %>% 
  group_by(subject, culture) %>%
  summarise(relational_choice = mean(as.numeric(resp)))

RMTS_plot <- ggplot(data = RMTS_raw, 
       aes(y = relational_choice, x = culture, fill = culture)) +
geom_flat_violin(position = position_nudge(x = .1, y = 0), alpha = .8) +
geom_point(aes(y = relational_choice, color = culture), 
           position = position_jitter(width = .15), size = .5, alpha = 0.8) +
geom_boxplot(width = .1, alpha = 0.3) +
scale_y_continuous(breaks = seq(0,1,0.5), 
                     labels = {function(x) paste0(as.character(x*100),"%")})+
scale_color_manual(values = c("red", "blue"))+
scale_fill_manual(values = c("red", "blue"))+
guides(fill = FALSE) +
guides(color = FALSE) +
scale_color_manual(values = c("red", "blue"))+
ylab("Proportion relational choice") + 
xlab("") +
theme_classic() + 
labs(title = "Ambiguous RMTS") +
theme(plot.title = element_text(hjust = 0.5, size = 8), 
      plot.subtitle = element_text(hjust = 0.5, size = 6), 
      text = element_text(size=8))
  # theme(text = element_text(size=28), 
  #       axis.text.x=element_blank(), 
  #       plot.margin=grid::unit(c(0,0,0,0), "mm")
  #       ) 


RMTS_plot
#raincloud_theme()
```

<!-- # Picture Free Description  -->
```{r FD_number}
FD_number <- tidy_d %>% 
  group_by(culture, task_info, resp_type) %>% 
  filter(task_info == "FD") %>% 
  mutate(
    FD_type = case_when(
      resp_type == "first_mention_focal" ~ "first_mention", 
      grepl("imada", resp_type) ~ "imada_count", 
      TRUE ~ "full_count"
    )
  ) %>% 
  group_by(culture, FD_type) %>% 
  summarise(
    mean = mean(as.numeric(resp)), 
    sd = sd(as.numeric(resp))
  )


```

```{r FD_plot, message=FALSE, warning=FALSE}
fd_ms <- tidy_d %>%
  filter(task_name == "FD") %>%
  filter(resp_type=="first_mention_focal" | grepl("imada", resp_type)) %>%
  group_by(subject, culture, resp_type) %>%
  summarise(mean_resp = mean(resp)) %>% 
  mutate(resp_print = case_when(
    resp_type == "imada_bckgrd_description" ~ "Background", 
    resp_type == "imada_focal_description" ~ "Focal", 
    resp_type == "first_mention_focal" ~ "First Mention"
  ))


FD_plot <- ggplot(data = filter(fd_ms, resp_type == "first_mention_focal"), 
       aes(y = mean_resp, x = culture, fill = culture)) +
geom_flat_violin(position = position_nudge(x = .1, y = 0), alpha = .8) +
geom_point(aes(y = mean_resp, color = culture), 
           position = position_jitter(width = .15), size = .5, alpha = 0.8) +
geom_boxplot(width = .1, alpha = 0.3) +
scale_y_continuous(breaks = seq(0,1,0.5), 
                     labels = {function(x) paste0(as.character(x*100),"%")})+
scale_color_manual(values = c("red", "blue"))+
scale_fill_manual(values = c("red", "blue"))+
guides(fill = FALSE) +
guides(color = FALSE) +
scale_color_manual(values = c("red", "blue"))+
ylab("Proportion of first mention focal") + 
xlab("")+
theme_classic() +
labs(title = "Picture Free Description")+
theme(text = element_text(size=8), 
      axis.title.y=element_text(size=5.5,face="bold"),
      plot.title = element_text(hjust = 0.5, size = 8), 
      plot.subtitle = element_text(hjust = 0.5, size = 8)
         #Eplot.margin=grid::unit(c(0,0,0,0), "mm")
         ) 
 

FD_plot
```

<!-- # Ebbinghaus illusion  -->
```{r}
IC_ms <- tidy_d %>%
  filter(task_name == "EBB") %>%
  filter(task_info %in% c("IL","NC")) %>%
  group_by(subject, task_info, trial_info, culture) %>%
  summarise(mean = mean(resp)) %>%
  group_by(task_info, trial_info, culture) %>%
  tidyboot_mean(mean, na.rm=T) %>% 
  mutate(
    task_info_print = case_when(
      task_info == "IL" ~ "Illusion", 
      task_info == "NC" ~ "No Context"
    )
  )

EBB_plot <- ggplot(IC_ms, aes(x = trial_info, y = mean, col = culture)) + 
  facet_wrap(~task_info_print) + 
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  geom_smooth(method = "lm", formula = y ~ x + I(x^2)) + 
  scale_color_manual(values = c("red", "blue"))+
scale_fill_manual(values = c("red", "blue"))+
  scale_y_continuous(breaks = seq(0,1,0.5), 
                     labels = {function(x) paste0(as.character(x*100),"%")})+
  ylab("Accuracy") + 
xlab("Size difference")+
  guides(color = FALSE)+
theme_classic()+
  theme(text = element_text(size=9))  
# +
#   theme(text = element_text(size=28), 
#         axis.text.x=element_blank(), 
#         plot.margin=grid::unit(c(0,0,0,0), "mm")
#         ) 
# 
#EBB_plot
```

<!-- # Horizon  -->
```{r HZ_plot}
# horizon height means
height_ms <- tidy_d %>%
  filter(task_name == "HZ") %>%
  filter(resp_type=="hz_height") 


HZ_plot <- ggplot(data = height_ms, 
       aes(y = as.numeric(resp), x = culture, fill = culture)) +
geom_flat_violin(position = position_nudge(x = .1, y = 0), alpha = .8) +
geom_point(aes(y = as.numeric(resp), color = culture), 
           position = position_jitter(width = .15), size = .5, alpha = 0.8) +
geom_boxplot(width = .1, alpha = 0.3) +
scale_y_continuous(breaks = seq(0,1,0.5), 
                     labels = {function(x) paste0(as.character(x*100),"%")})+
scale_color_manual(values = c("red", "blue"))+
scale_fill_manual(values = c("red", "blue"))+
guides(fill = FALSE) +
guides(color = FALSE) +
scale_color_manual(values = c("red", "blue"))+
ylab("Horizon height on canvas") + 
xlab("")+
theme_classic() + 
labs(title = "Horizon Collage") +
theme(plot.title = element_text(hjust = 0.5, size = 8), 
      plot.subtitle = element_text(hjust = 0.5, size = 6),
      text = element_text(size=8))
# +
#   theme(text = element_text(size=28), 
#         axis.text.x=element_blank(), 
#         plot.margin=grid::unit(c(0,0,0,0), "mm")
#         ) 
HZ_plot
```



<!-- # Symbolic Self Inflation  -->
```{r SI_plot}
si_ratio_ms <- tidy_d %>%
  filter(task_name == "SI")  %>%
  filter(resp_type == "inflation_score_ratio") 

#plot pen choice means
SI_plot <- ggplot(data = si_ratio_ms, 
       aes(y = as.numeric(resp), x = culture, fill = culture)) +
geom_flat_violin(position = position_nudge(x = .1, y = 0), alpha = .8) +
geom_point(aes(y = as.numeric(resp), color = culture), 
           position = position_jitter(width = .15), size = .5, alpha = 0.8) +
geom_boxplot(width = .1, alpha = 0.3) +
scale_y_continuous(breaks = seq(0,6,2), 
                     labels = {function(x) paste0(as.character(x*100),"%")})+
scale_color_manual(values = c("red", "blue"))+
scale_fill_manual(values = c("red", "blue"))+
guides(fill = FALSE) +
guides(color = FALSE) +
scale_color_manual(values = c("red", "blue"))+
ylab("Inflation score") + 
xlab("")+
theme_classic() +
labs(title = "Symbolic Self-Inflation") +
theme(plot.title = element_text(hjust = 0.5, size = 8), 
      plot.subtitle = element_text(hjust = 0.5, size = 6), 
      text = element_text(size=8))
# # +
#   theme(text = element_text(size=28), 
#         axis.text.x=element_blank(), 
#         plot.margin=grid::unit(c(0,0,0,0), "mm")
#         ) 
SI_plot
```

<!-- # Uniqueness Preference  -->
```{r UP_plot}
pen_raw <- tidy_d %>%
  filter(task_name == "CP") 



UP_plot <- ggplot(data = pen_raw, 
       aes(y = resp, x = culture, fill = culture)) +
geom_flat_violin(position = position_nudge(x = .1, y = 0), alpha = .8) +
geom_point(aes(y = resp, color = culture), 
           position = position_jitter(width = .15, height = .15), size = .5, alpha = 0.8) +
geom_boxplot(width = .1, alpha = 0.3) +
scale_y_continuous(breaks = seq(0,1,0.5), 
                     labels = {function(x) paste0(as.character(x*100),"%")})+
scale_color_manual(values = c("red", "blue"))+
scale_fill_manual(values = c("red", "blue"))+
guides(fill = FALSE) +
guides(color = FALSE) +
scale_color_manual(values = c("red", "blue"))+
ylab("Preference for unique option") + 
xlab("")+
theme_classic() + 
labs(title = "Uniqueness Preference") +
theme(plot.title = element_text(hjust = 0.5, size = 8), 
      plot.subtitle = element_text(hjust = 0.5, size = 6),
      text = element_text(size=8))  
# +
  # theme(text = element_text(size=28), 
  #       axis.text.x=element_blank(), 
  #       plot.margin=grid::unit(c(0,0,0,0), "mm")
  #       ) 
UP_plot
```




<!-- # Causal Attribution  -->
```{r CA_plot}
CA_ms <- tidy_d %>%
  filter(task_name == "CA") %>% 
  group_by(culture, resp_type, subject) %>%
  summarise(subject_mean = mean(resp)) %>% 
  mutate(resp_type_print = case_when(
    resp_type == "person_attribution" ~ "Person Attribution", 
    resp_type == "situation_attribution" ~ "Situation Attribution"
  ))


#plot means and CIs
CA_plot <- ggplot(data = CA_ms, 
       aes(y = subject_mean, x = culture, fill = culture)) +
geom_flat_violin(position = position_nudge(x = .1, y = 0), alpha = .8) +
geom_point(aes(y = subject_mean, color = culture), 
           position = position_jitter(width = .15), size = .5, alpha = 0.8) +
geom_boxplot(width = .1, alpha = 0.3) +
scale_color_manual(values = c("red", "blue"))+
scale_fill_manual(values = c("red", "blue"))+
guides(fill = FALSE) +
guides(color = FALSE) +
scale_color_manual(values = c("red", "blue"))+
ylab("Average number") + 
xlab("")+
theme_classic() +
#   theme(text = element_text(size=28), 
#         axis.text.x=element_blank(), 
#         plot.margin=grid::unit(c(0,0,0,0), "mm")
#         )  + 
  facet_wrap(~resp_type_print)+
  labs(title = "Causal Attribution") +
theme(text = element_text(size=8),
      plot.title = element_text(hjust = 0.5, size = 8), 
      plot.subtitle = element_text(hjust = 0.5, size = 6))  
CA_plot
```


<!-- see figure \ref{fig1}. -->

<!-- ![picture \label{fig1}](figs/Big_Fig.png) -->

```{r bigfig, fig.env = "figure*", fig.pos = "ht", fig.width=6.5, fig.height=3.3, fig.align = "center", fig.cap = "Results from each task. Data from China are shown in red (\\textit{N} = 151) and from the US in Blue (\\textit{N} = 105). Only the Picture Free Description task shows a cross-cultural difference."}
big_fig <- cowplot::plot_grid(RMTS_plot, SI_plot, HZ_plot, UP_plot, FD_plot, CA_plot)
ggsave(here("writeups/CCRR_CogSci/figs/Big_Fig.png"), big_fig, 
       width = 6.5, height = 3.9, device = NULL)

library(png)
library(grid)
img <- readPNG(here("writeups/CCRR_CogSci/figs/Big_Fig.png"))
 grid.raster(img)
 
#RMTS_plot+SI_plot+HZ_plot+UP_plot+FD_plot+CA_plot+ plot_layout(ncol = 3)
#fig.width=6.5, fig.height=3.9,
```

```{r label = "ebb", fig.env = "figure", fig.pos = "h", fig.align = "center", fig.height = 1.8, fig.cap = "Figure 2:  Results from Ebbinghaus Illusion. The x-axis shows size difference between the two circles (in percent), with judgment accuracy plotted on the y-axis. The red (China) and blue (US) lines show changes in accuracy as a function of circle size difference and condition. There is no cross-cultural difference."}
EBB_plot
```


### Ambiguous RMTS
```{r RMTS_model}
rmts_df <- df.main %>% 
  filter(task_name == "RMTS") %>% 
  mutate(choice = as.factor(case_when(
    resp == "1" ~ "rel",
    resp == "0" ~ "obj"))
         ) %>%
  group_by(subject) %>% 
  mutate(trial_num = as.factor(row_number())) %>% 
  select(-resp, -task_info, -trial_info, -resp_type)
# model 0: not converging 
#rmts_model <- glmer(choice ~ culture + (trial_num | subject), family = binomial, data = rmts_df)

# model 1: 
rmts_model <- glmer(choice ~ culture + (1 | subject), family = binomial, data = rmts_df)
rmts_tidy_model <- tidy_model_table(rmts_model)
```

```{r RMTS_summary, warning=FALSE}


RMTS_summary <- df.main %>% 
  filter(task_name == "RMTS") %>% 
  group_by(culture, subject) %>% 
  summarise(
    relational_match = mean(resp)
  ) %>% 
  group_by(culture) %>% 
  summarise(
    culture_mean = round(mean(relational_match),2), 
    culture_sd = round(sd(relational_match),2)
  )
  
#RMTS_summary
```


We ran a mixed-effects logistic regression predicting response choice (object or relation) with country (US or China) as a fixed effect. We included an intercept per subject as a random effect, as well as by-subject random slopes for trial number to model order effects. This model did not converge; following lab standard operating procedures, we pruned the random slopes for trial number. There was no main effect of country on response choice (object or relation; US: *M* = `r filter(RMTS_summary, culture == "US")$culture_mean`; CN: *M* = `r filter(RMTS_summary, culture == "CN")$culture_mean`; $\beta$ = `r filter(rmts_tidy_model, predictor == "cultureUS")$estimate_print`, *SE* = `r filter(rmts_tidy_model, predictor == "cultureUS")$se_print`, *z* = `r filter(rmts_tidy_model, predictor == "cultureUS")$z_print`, *p* `r filter(rmts_tidy_model, predictor == "cultureUS")$p_print`). The preference for object-based solutions seen in US preschoolers and the corresponding preference for relational solutions observed in Chinese preschoolers in an ambiguous context did not extent to adults in our samples.
<!--
These US results replicate findings by @goddu2018toddlers, who reported that US adults are at chance in this paradigm, but also show in an additional experiment that they track evidence for both solutions: when forced to choose between correct and incorrect object and relational options (rather than the ambiguous choice options presented here) US adults succeed in selecting appropriate object and relation solutions. It seems likely that adults in both groups of our study are aware of the ambiguous evidence and their near-chance selections reflect (reasonable) uncertainty. Future research should address the developmental trajectory between complementary bias in American and Chinese 3-year-olds and comparable adult performance across these cultures. Do 3-year-olds spontaneously track both options, as 18-month-olds and adults do in Goddu and Walker? If not, does their apparent bias disappear once they begin to track evidence for both alternatives?
-->



### Picture Free Description 

```{r FD_summary}
fd_summary <- df.main %>% 
  filter(task_name == "FD") %>% 
  group_by(culture, subject, resp_type) %>% 
  summarise(
    mean_resp = mean(resp)
  ) %>% 
  group_by(culture, resp_type) %>% 
  summarise(
    culture_mean = round(mean(mean_resp),2)
  )

```

```{r fd_first_mention_model}
mention_df <- df.main %>% 
  filter(task_name == "FD", resp_type == "first_mention_focal") %>% 
    mutate(first_mention = as.factor(case_when(
    resp == "1" ~ "focal",
    resp == "0" ~ "background")), 
    scene = trial_info) %>% 
  select(-resp, -task_info, -resp_type, -trial_info)

#mention_model <- glmer(first_mention ~ culture + (1 | subject)+(culture | scene), family = binomial, data = mention_df)
#Error: number of observations (=1146) < number of random effects (=1148) for term (scene | subject); the random-effects parameters are probably unidentifiable

mention_model <- glmer(first_mention ~ culture + (1 | subject) , 
                   family = binomial, data = mention_df)

tidy_fd_mention_model <- tidy_model_table(mention_model)


```

```{r fd_imada_model}
fd_imada <- df.main %>% 
  filter(task_name == "FD") %>%
  filter(grepl("imada", resp_type)) %>%
  mutate(description_num = as.numeric(resp),
         scene = trial_info,
         description_type = factor(resp_type)) %>% 
  select(-resp, -task_info, -resp_type, -trial_info)

# model i: fail to converge imada_model <- glmer(description_num ~ description_type * culture + (description_type | subject) + (culture | scene), family=gaussian, data = fd_imada) #Model failed to converge with max|grad| = 0.00453746 (tol = 0.002, component 1)

imada_model <- lmer(description_num ~ description_type * culture + (1 | subject) , data = fd_imada)


#fd_model
tidy_imada_model <- tidy_model_table_for_t(imada_model)



```



 We selected this task to investigate whether there are cultural differences in visual attention, as measured by the content of picture descriptions. Based on Imada et al.'s [-@imada2013east] findings, we expected Chinese participants would be more likely to mention background objects first and provide more descriptive accounts for background objects relative to focal objects, in comparison with US participants. Our results extend previous findings with the former metric (first mention; US: *M* = `r filter(fd_summary, culture == "US"&resp_type == "first_mention_focal")$culture_mean`; CN: *M* = `r filter(fd_summary, culture == "CN"&resp_type == "first_mention_focal")$culture_mean`), but not the latter (number of descriptive accounts; For focal objects: US: *M* = `r filter(fd_summary, culture == "US"&resp_type == "imada_focal_description")$culture_mean`; CN: *M* = `r filter(fd_summary, culture == "CN"&resp_type == "imada_focal_description")$culture_mean`; For background objects: US: *M* = `r filter(fd_summary, culture == "US"&resp_type == "imada_bckgrd_description")$culture_mean`; CN: *M* = `r filter(fd_summary, culture == "CN"&resp_type == "imada_bckgrd_description")$culture_mean`). For first mention, we ran a mixed-effects logistic regression predicting the type of first mention (object or relation) with country (US or China) as a fixed effect and subject as random effect. We found a main effect of country ($\beta$ = `r filter(tidy_fd_mention_model, predictor == "cultureUS")$estimate_print`, *SE* = `r filter(tidy_fd_mention_model, predictor == "cultureUS")$se_print`, *z* = `r filter(tidy_fd_mention_model, predictor == "cultureUS")$z_print`, *p* `r filter(tidy_fd_mention_model, predictor == "cultureUS")$p_print`). For descriptive accounts, we ran a mixed-effect Poisson regression model predicting the number of descriptive accounts, with the interaction between description type (focal or background) and country (US or China) as fixed effect, description type and subject as random effect, and by-picture random slope for country. The model failed to converge. Following the standard pruning procedure, we ran a mixed effect model with the interaction term as fixed effect and the subject as random effect. There was no interaction between culture and description type ($\beta$ = `r filter(tidy_imada_model, predictor == "description_typeimada_focal_description:cultureUS")$estimate_print`, *SE* = `r filter(tidy_imada_model, predictor == "description_typeimada_focal_description:cultureUS")$se_print`, *t* = `r filter(tidy_imada_model, predictor == "description_typeimada_focal_description:cultureUS")$t_print`, *p* `r filter(tidy_imada_model, predictor == "description_typeimada_focal_description:cultureUS")$p_print`). But the main effects of culture and description type were significant (Culture, with US participants provide more descriptions overall: $\beta$ = `r filter(tidy_imada_model, predictor == "cultureUS")$estimate_print`, *SE* = `r filter(tidy_imada_model, predictor == "cultureUS")$se_print`, *t* = `r filter(tidy_imada_model, predictor == "cultureUS")$t_print`, *p* `r filter(tidy_imada_model, predictor == "cultureUS")$p_print`; Description type, with more descriptions on the background objects: $\beta$ = `r filter(tidy_imada_model, predictor == "description_typeimada_focal_description")$estimate_print`, *SE* = `r filter(tidy_imada_model, predictor == "description_typeimada_focal_description")$se_print`, *t* = `r filter(tidy_imada_model, predictor == "description_typeimada_focal_description")$t_print`, *p* `r filter(tidy_imada_model, predictor == "description_typeimada_focal_description")$p_print`) 

<!--
Our results extend Imada et al.'s [-@imada2013east] findings to Chinese adults, suggesting that enhanced visual sensitivity to contextual information is also present in China. This is not surprising in light of the theoretical account postulating the East-West differences can be characterized as holistic-analytic cognitive style differences, which may originate from the early days of ancient China and ancient Greek, respectively [@nisbett2001culture]. Throughout history, Chinese civilizations established and influenced many sociocultural norms in East Asia, including Japan. This shared cultural background can explain the successful extension of Imada et al.'s [-@imada2013east] finding to Chinese adults. 
-->

### Ebbinghaus Illusion 
```{r EBB_summary}

ebb_summary <- df.main %>% 
  filter(task_name == "EBB") %>% 
  group_by(culture, subject, task_info) %>% 
  summarise(
    mean_resp = mean(resp)
  ) %>% 
  group_by(culture, task_info) %>% 
  summarise(
    culture_mean = round(mean(mean_resp),2)
  )


```
```{r}

ebb_df <- read.csv(PROCESSED_MAIN_PATH) %>% 
  filter(task_name == "EBB", task_info != "HELPFUL") %>% 
  mutate(correct = as.factor(case_when(
    resp == "1" ~ "correct",
    resp == "0" ~ "incorrect")), 
         context = task_info, 
         size_diff = as.numeric(trial_info), 
         ) %>% 
  select(-resp, -task_info, -trial_info)

  
#full model
#ebb_model <- glmer(correct ~ culture * context * size_diff + (size_diff * context | subject), family = binomial, data = ebb_df, control=glmerControl(optimizer="bobyqa"))
#convergence code 1 from bobyqa: bobyqa -- maximum number of function evaluations exceeded
#boundary (singular) fit: see ?isSingular

#model 2 (if full does not converge)
#ebb_model <- glmer(correct ~ culture * context * size_diff + (context | subject), family = binomial, data = ebb_df, control=glmerControl(optimizer="bobyqa"))
#boundary (singular) fit: see ?isSingular


#model 3
ebb_model <- glmer(correct ~ culture * context * size_diff + ( 1 | subject), family = binomial, data = ebb_df, control=glmerControl(optimizer="bobyqa"))



#ebb_model
#summary(ebb_model)

tidy_ebb_mention_model <- tidy_model_table(ebb_model)
#View(tidy_ebb_mention_model)
```


This task was included as a second measurement for cultural differences in visual attention. @imada2013east found that Japanese children are more susceptible to Ebbinghaus illusion than US children. To test whether perception of the Ebbinghaus illusion varied across populations in our sample, we ran a mixed-effects logistic regression predicting accuracy on each trial, with country (US or China), context (No Context or Illusion Context), and circle size difference (the percent of difference in diameters) as fixed effects, with their interactions. As random effects, we included intercepts for subjects, as well as by-subject random slopes for the effect of condition. We found main effects of context (with worse performance in the Illusion Context; $\beta$ = `r filter(tidy_ebb_mention_model, predictor == "contextNC")$estimate_print`, *SE* = `r filter(tidy_ebb_mention_model, predictor == "contextNC")$se_print`, *z* = `r filter(tidy_ebb_mention_model, predictor == "contextNC")$z_print`, *p* `r filter(tidy_ebb_mention_model, predictor == "contextNC")$p_print`) and circle size difference (worse performance for smaller differences; $\beta$ = `r filter(tidy_ebb_mention_model, predictor == "size_diff")$estimate_print`, *SE* = `r filter(tidy_ebb_mention_model, predictor == "size_diff")$se_print`, *z* = `r filter(tidy_ebb_mention_model, predictor == "size_diff")$z_print`, *p* `r filter(tidy_ebb_mention_model, predictor == "size_diff")$p_print`), but no main effects of or interactions with country (All $\beta$ < 0.01; All *p* > 0.05). 
<!--
We failed to extend the cultural-differences in the susceptibility to Ebbinghaus illusion to U.S. and Chinese adults. One interpretation for the current null-finding is that it reveals an important limitation on generalizability. There might be significant within-culture differences that cause the bias in visual attention assessed by the Ebbinghaus illusion task to be present in Japan, but not China. If this is the case, then future research needs to examine the within-culture differences more rigorously: what are some socio-cultural factors that are present in Japan but absent in China (or vice versa) that discourage the attention biases assessed by Ebbinghaus illusion in Chinese adults? An alternative possibility is that the cultural differences in this task might only be present in children, with adults in both China and the US reaching ceiling level. To our knowledge, there has not been systematic investigation in the East-West differences in Ebbinghaus illusion development beyond childhood. Therefore it remains an empirical question whether the Ebbinghaus illusion cultural differences is limited in some specific countries, or whether it is limited in certain age groups. 
-->

### Horizon Collage 

```{r HZ_table}
HZ_height_df <- df.main %>% 
  filter(task_name == "HZ", resp_type == "hz_height") %>% 
  mutate(
    height = resp
         ) %>% 
  select(-resp, -task_info, -trial_info)

HZ_height_model <- lm(height ~ culture, 
                      data = HZ_height_df)

HZ_stkr_area_df <- df.main %>% 
  filter(task_name == "HZ", resp_type == "stkr_area") %>% 
  mutate(
    stkr_area = (resp/(75*75*3*3)),2) %>% 
#3 from scaling, 75 from conversion: http://auctionrepair.com/pixels.html, 

  select(-resp, -task_info, -trial_info)

HZ_stkr_area_model <- lm(stkr_area ~ culture, 
                      data = HZ_stkr_area_df)

HZ_stkr_n_df <- df.main %>% 
  filter(task_name == "HZ", resp_type == "stkr_count") %>% 
  mutate(
    stkr_count = resp
         ) %>% 
  select(-resp, -task_info, -trial_info)

HZ_stkr_n_model <- lm(stkr_count ~ culture, 
                      data = HZ_stkr_n_df)

HZ_height_tidy <- tidy_model_table_for_t(HZ_height_model)
HZ_count_tidy <- tidy_model_table_for_t(HZ_stkr_n_model)
HZ_stkr_area_tidy <- tidy_model_table_for_t(HZ_stkr_area_model)

```


```{r HZ_summary}

hz_summary <- df.main %>% 
  filter(task_name == "HZ") %>% 
  group_by(culture, subject, task_info, resp_type) %>% 
  summarise(
    mean_resp = mean(resp)
  ) %>% 
  group_by(culture, task_info, resp_type) %>% 
  summarise(
    culture_mean = round(mean(mean_resp),2)
  ) %>% 
  mutate(
    culture_mean = case_when(
      (resp_type == "stkr_area") ~ round((culture_mean/(75*75*3*3)),2), #3 from scaling, 75 from conversion: http://auctionrepair.com/pixels.html, 
      TRUE ~ culture_mean 
    )
  )


```


In the Horizon Collage task, three key measurements are calculated from the “collage” participants created: the height of the horizon (height in proportion to the height of the frame), the number of stickers, and the total area of the stickers covered (following the original analysis, we added up the area occupied by each individual sticker). In @senzaki2014holistic, they found that Japanese children tend to put the horizon higher and include more stickers that cover more area in their collage, compared to the Canadian children. We ran a fixed effect linear model with culture as the main predictor for each of the measurements. We found that culture did not significantly predict any of the three measurements (Sticker height: US: *M* = `r filter(hz_summary, culture == "US"&resp_type == "hz_height")$culture_mean`; CN: *M* = `r filter(hz_summary, culture == "CN"&resp_type == "hz_height")$culture_mean`; Sticker number: US: *M* = `r filter(hz_summary, culture == "US"&resp_type == "stkr_count")$culture_mean`; CN: *M* = `r filter(hz_summary, culture == "CN"&resp_type == "stkr_count")$culture_mean`; Sticker area: US: *M* = `r filter(hz_summary, culture == "US"&resp_type == "stkr_area")$culture_mean`; CN: *M* = `r filter(hz_summary, culture == "CN"&resp_type == "stkr_area")$culture_mean`; All $\beta$ < 0.03; All *p* > 0.1). 
<!--
The failure to extend the cultural differences in collage-making to Chinese adults and U.S. adults are unlikely to be caused by the differences in age groups. @senzaki2014holistic found that the cultural differences were more salient in older children than younger children. 
They suggested that the emerging cultural differences can be explained by the process of internalization of one’s culture-specific aesthetic preferences and attention style throughout development. This leads to an alternative interpretation: might it be due to the differences in visual traditions between Japan and China that prevents generalization? This remains an open question. Studies that examine visual traditions and aesthetic styles in the history did not differentiate the paintings’ country of origins, but used “East Asian paintings” as an umbrella term to refer to them [@masuda2008culture]. Finer-grained analysis of visual traditions is needed to warrant better assessment of its influence on cultural differences in visual attention style.
-->

### Symbolic Self-inflation

```{r SI_model}
si_df_r <- df.main %>% 
  filter(task_name == "SI") %>% 
  filter(resp_type == "inflation_score_ratio") %>% 
  mutate(score = resp) %>% 
  select(-resp, -task_info, -trial_info, -resp_type)


si_df_diff <- df.main %>% 
  filter(task_name == "SI") %>% 
  filter(resp_type == "inflation_score_diff") %>% 
  mutate(score = resp) %>% 
  select(-resp, -task_info, -trial_info, -resp_type)

si_model_r <- glm(score ~ culture, family=gaussian, data = si_df_r)
si_model_diff <- glm(score ~ culture, family=gaussian, data = si_df_diff)

si_r_tidy <- tidy_model_table_for_t(si_model_r)
si_d_tidy <- tidy_model_table_for_t(si_model_diff)
```


```{r SI_summary}
si_summary <- df.main %>% 
  filter(task_name == "SI") %>% 
  group_by(culture, subject, task_info, resp_type) %>% 
  summarise(
    mean_resp = mean(resp)
  ) %>% 
  group_by(culture, task_info, resp_type) %>% 
  summarise(
    culture_mean = round(mean(mean_resp),2), 
    #culture_mean = mean(mean_resp), 
    culture_sd = round(mean(mean_resp),2), 
    #culture_sd = sd(mean_resp),
  )

```

<!-- This first task in the social cognition category was included as a measure of self-concept, aiming at testing whether the larger symbolic self observed in US adults when compared with Japanese adults [] extends to the comparison between adults in the US and China.  -->
We ran a linear regression predicting percent inflation score (calculated by dividing the diameter of the self circle by the average diameter of circles for others) with country (US or China) as a fixed effect. No difference was found in the degree of symbolic self-inflation between US and China adults based on percent inflation scores (US *M* = `r filter(si_summary, culture == "US", resp_type == "inflation_score_ratio")$culture_mean`; CN *M* = `r filter(si_summary, culture == "CN", resp_type == "inflation_score_ratio")$culture_mean`; $\beta$ 
`r filter(si_r_tidy, predictor == "cultureUS")$estimate_print`, *SE* = `r filter(si_r_tidy, predictor == "cultureUS")$se_print`, *t* = `r filter(si_r_tidy, predictor == "cultureUS")$t_print`, *p* `r filter(si_r_tidy, predictor == "cultureUS")$p_print`). In order to test whether this null finding resulted from the different ways of calculating inflation scores between our study and Kitayama et al.'s [-@kitayama2009cultural] original study, we then tried to do a replication of the original analyses, using subtraction-based inflation scores (which may be subject to baseline effects). The degree of self-inflation still did not differ significantly between US and Chinese adults (US *M* = `r filter(si_summary, culture == "US", resp_type == "inflation_score_diff")$culture_mean`; CN *M* = `r filter(si_summary, culture == "CN", resp_type == "inflation_score_diff")$culture_mean`; $\beta$ = 
`r filter(si_d_tidy, predictor == "cultureUS")$estimate_print`, *SE* = `r filter(si_d_tidy, predictor == "cultureUS")$se_print`, *t* = `r filter(si_d_tidy, predictor == "cultureUS")$t_print`, *p* `r filter(si_d_tidy, predictor == "cultureUS")$p_print`).
<!--
One possible explanation for our null results is that we adopted a different task design from @kitayama2009cultural. Instead of asking participants to draw their social network, our design asked participants to draw themselves and the family members they grew up with. During the coding process, we noticed that people from both cultures tended to draw older people, e.g., their parents, into larger circles, which might have resulted in overall larger circles for other people than the self-circles in our task for both cultures, masking any US-China difference in the degree of self-inflation. It is possible that there are also cultural differences between Japan and China. Multiple existing studies on self-concept done with both Japanese and Chinese samples have shown that Japanese samples typically demonstrate more robust characteristics previously associated with East Asian cultures in general, with Chinese samples deviating from these characteristics at times [@bailey1997conceptions; @church2012self; @church2014relating]. While this remains a question worthy of further investigation with future studies, it is unlikely that cultural differences between Japan and China have led to the null result in our study. It cannot explain the reason why US participants drew their self-circles smaller than the circles for others in our study, but bigger than the circles for others in Kitayama et al.'s [-@kitayama2009cultural] original study.
-->

### Uniqueness Preference

```{r cp_model}
cp_df <- df.main %>% 
  filter(task_name == "CP") %>% 
  mutate(choice = as.factor(case_when(
    resp == "1" ~ "uniq",
    resp == "0" ~ "non_uniq"))
         ) %>% 
  select(-resp, -task_info, -trial_info, -resp_type)

cp_model <- glm(choice ~ culture, 
                   family=binomial(link="logit"),
                  data = cp_df)

cp_tidy_d <- tidy_model_table(cp_model)

```

```{r cp_summary}
cp_summary <- df.main %>% 
  filter(task_name == "CP") %>% 
  group_by(culture) %>% 
  summarise(
    culture_mean = round(mean(resp),2), 
    #culture_mean = mean(mean_resp), 
    culture_sd = round(mean(resp),2), 
    #culture_sd = sd(mean_resp),
  )
```

<!-- As the second task measuring social cognition, this task was included to examine cross-cultural preferences for uniqueness.  -->
We ran a simple logistic regression predicting each participant’s single choice (minority or majority color) with country (US or China) as a fixed effect. No cross-cultural difference was found in the likelihood of choosing the uniquely colored sticker (US: *M* = `r filter(cp_summary, culture == "US")$culture_mean`; CN: *M* = `r filter(cp_summary, culture == "CN")$culture_mean`; $\beta$ = 
`r filter(cp_tidy_d, predictor == "cultureUS")$estimate_print`, *SE* = `r filter(cp_tidy_d, predictor == "cultureUS")$se_print`, *z* = `r filter(cp_tidy_d, predictor == "cultureUS")$z_print`, *p* `r filter(cp_tidy_d, predictor == "cultureUS")$p_print`). Therefore, we did not find support for the hypothesis that US adults are more likely to show a preference for uniqueness.
<!--
The difference between our result and that of the original study by @kim1999deviance might be related to the use of online format in our study. In the original study, participants were asked to pick a gift pen from five physical pens with different barrel colors. It could be that Asian American participants in the previous study chose the more common color because they wanted the next person to also have room for decision making in the face of resource scarcity, or because they were expressing values or identities influenced by East Asian cultural mandates favoring interpersonal harmony and similarity. It’s possible that adapting the task to an online format in which resource scarcity was not strictly real and choices in this task had no lasting effect (in the form of a new pen), may have trivialized the choice and undermined the incentive for prosocial, harmonious behavior of expression of values. This possibility is consistent with the chance responding we observed in both groups.
-->

### Causal Attribution 

```{r CA_model}
ca_df <- df.main %>% 
  filter(task_name == "CA") %>% 
  mutate(attrib_num = as.numeric(resp),
         attrib_binary = replace(attrib_num, attrib_num > 1, 1),
         trial = trial_info,
         attrib_type = factor(resp_type)) %>% 
  select(-resp, -task_info)

#ca_model <- glmer(attrib_num ~ attrib_type * culture + (attrib_type | subject) + (culture | trial), family=poisson, data = ca_df, control=glmerControl(optimizer="bobyqa"))
#boundary (singular) fit: see ?isSingular

#ca_model_binary <- glmer(attrib_binary ~ attrib_type * culture + (attrib_type | subject) + (culture | trial), family=binomial, data = ca_df, control=glmerControl(optimizer="bobyqa"))
#boundary (singular) fit: see ?isSingular

#ca_model1 <- glmer(attrib_num ~ attrib_type * culture + (attrib_type | subject) + (1 | trial), family=poisson, data = ca_df, control=glmerControl(optimizer="bobyqa"))
#boundary (singular) fit: see ?isSingular

#ca_model2 <- glmer(attrib_num ~ attrib_type * culture + (1 | subject) + (1 | trial), family=poisson, data = ca_df, control=glmerControl(optimizer="bobyqa"))
#boundary (singular) fit: see ?isSingular

#ca_model3 <- glmer(attrib_num ~ attrib_type * culture + (1 | subject), family=poisson, data = ca_df, control=glmerControl(optimizer="bobyqa"))
#boundary (singular) fit: see ?isSingular

ca_model4 <- glm(attrib_num ~ attrib_type * culture, family=poisson, data = ca_df)

ca_tidy_table <- tidy_model_table(ca_model4)
#ca_tidy_table
```


```{r CA_summary}
CA_summary <- tidy_d %>% 
  group_by(culture, task_info, resp_type, subject) %>% 
  filter(task_info == "CA") %>%
  summarise(
    sbj_resp = mean(resp)
  ) %>% 
  ungroup() %>% 
  group_by(culture, resp_type) %>% 
  summarise(
    culture_mean = round(mean(sbj_resp),2), 
    sd = sd(sbj_resp)
  )
```

To test whether Chinese participants tended to make more situational attributions, and US adults more personal attributions, we ran a mixed-effects Poisson regression predicting the number of attributions included in each explanation, with attribution type (situation or person), country (US or CN), and their interaction as fixed effects and subject and trial as random effects, with by-subject random slopes for attribution type and by-trial random slopes for country. We found a main effect of description type (With more situation attribution than person attribution. Situation attribution: US: *M* = `r filter(CA_summary, culture == "US" & resp_type == "situation_attribution")$culture_mean`; CN: *M* = `r filter(CA_summary, culture == "CN" & resp_type == "situation_attribution")$culture_mean`; Person attribution: US: *M* = `r filter(CA_summary, culture == "US" & resp_type == "person_attribution")$culture_mean`; CN: *M* = `r filter(CA_summary, culture == "CN" & resp_type == "person_attribution")$culture_mean`; $\beta$ = `r filter(ca_tidy_table, predictor == "attrib_typesituation_attribution")$estimate_print`, *SE* = `r filter(ca_tidy_table, predictor == "attrib_typesituation_attribution")$se_print`, *z* = `r filter(ca_tidy_table, predictor == "attrib_typesituation_attribution")$z_print`, *p* `r filter(ca_tidy_table, predictor == "attrib_typesituation_attribution")$p_print`
). Neither the interaction nor the main effect of culture was significant (Both $\beta$ < 0.3; *p* > 0.05).


### Raven's SPM 

```{r raven_summary, message=FALSE, warning=FALSE}
raven_summary <- df.main %>% 
  filter(task_name == "RV") %>% 
  group_by(culture, subject) %>% 
  summarise(
    accuracy = mean(resp)
  ) %>% 
  group_by(culture) %>% 
  summarise(
    culture_mean = round(mean(accuracy),2)
  )

rv_df <- df.main %>% 
  filter(task_name == "RV") %>% 
  mutate(acc = as.numeric(resp)) %>% 
  group_by(subject) %>% 
  mutate(trial = as.factor(row_number())) %>% 
  select(-resp, -task_info, -trial_info, -resp_type)

rv_model <- glmer(acc ~ culture + (1 | subject) + (culture | trial), family = binomial, data = rv_df)

tidy_rv_model <- tidy_model_table(rv_model)
```

We ran a mixed-effects logistic regression predicting per-trial accuracy, with country as a fixed effect, random intercepts for each subject and question, and by-question random slopes for country. We found a main effect of country, with Chinese participants outperforming those from the US (US: *M* = `r filter(raven_summary, culture == "US")$culture_mean`; CN: *M* = `r filter(raven_summary, culture == "CN")$culture_mean`; $\beta$ = `r filter(tidy_rv_model, predictor == "cultureUS")$estimate_print`, *SE* = `r filter(tidy_rv_model, predictor == "cultureUS")$se_print`, *z* = `r filter(tidy_rv_model, predictor == "cultureUS")$z_print`, *p* `r filter(tidy_rv_model, predictor == "cultureUS")$p_print`). This finding replicates @su2020analogical in finding an advantage on this measure. In our context, we interpret the relatively high scores we observed as evidence that participants were engaging fully with our tasks. 
 
